import { ColumnInfo, AiDecision } from '@/types/dashboard';

/**
 * OpenAI Proxy Service (via Python Engine)
 *
 * Agora as chamadas s√£o roteadas pelo backend Python para evitar CORS
 * e proteger a API Key.
 */

const PYTHON_API_URL = import.meta.env.VITE_PYTHON_API_URL;

if (!PYTHON_API_URL) {
  throw new Error(
    "ERRO CR√çTICO: A vari√°vel de ambiente VITE_PYTHON_API_URL n√£o est√° definida. " +
    "Verifique o arquivo .env e fa√ßa rebuild do frontend."
  );
}

/**
 * Solicita gera√ß√£o de widget para o dashboard via Proxy Python
 */
export async function askOpenAIForWidget(
  userId: string,
  dashboardId: string,
  prompt: string,
  context: {
    columns: any[];
    semanticMap: any[];
    intent: any;
    rowCount: number;
    fileName: string;
    sourceId?: string;
    semanticDatasetId?: string;
  }
): Promise<{ status: 'success' | 'error'; widgetConfig?: any; type?: 'metric' | 'chart'; message?: string }> {
  console.log('üé® [OpenAI Proxy] Widget Request:', { prompt, dashboardId });

  try {
    const response = await fetch(`${PYTHON_API_URL}/ai/ask-widget`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        user_id: userId,
        dashboard_id: dashboardId,
        prompt,
        context,
      }),
    });

    if (!response.ok) {
      throw new Error(`HTTP Error ${response.status}`);
    }

    const data = await response.json();
    return data;

  } catch (error) {
    console.error('üî• [OpenAI Proxy] Error:', error);
    return {
      status: 'error',
      message: error instanceof Error ? error.message : 'Erro ao conectar via proxy de IA.',
    };
  }
}

/**
 * Solicita gera√ß√£o de f√≥rmula para coluna calculada via Proxy Python
 */
export async function askOpenAIForFormula(
  userId: string,
  prompt: string,
  context: {
    columns: any[];
    fileName: string;
    dashboardId: string;
  }
): Promise<{ status: 'success' | 'error'; columnName?: string; formula?: string; message?: string }> {
  console.log('üìê [OpenAI Proxy] Formula Request:', { prompt, dashboardId: context.dashboardId });

  try {
    const response = await fetch(`${PYTHON_API_URL}/ai/ask-formula`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        user_id: userId,
        prompt,
        context,
      }),
    });

    if (!response.ok) {
      throw new Error(`HTTP Error ${response.status}`);
    }

    const data = await response.json();
    return data;

  } catch (error) {
    console.error('üî• [OpenAI Proxy] Error:', error);
    return {
      status: 'error',
      message: error instanceof Error ? error.message : 'Erro ao conectar via proxy de f√≥rmula.',
    };
  }
}

/**
 * Chat livre (n√£o implementado no proxy ainda, mas mantemos a assinatura)
 */
export async function chatWithAssistant(
  dashboardId: string,
  message: string,
  context?: any
): Promise<{ status: 'success' | 'error'; response?: string; message?: string }> {
  console.warn('‚ö†Ô∏è [OpenAI Proxy] Chat not implemented');
  return { status: 'error', message: 'Chat n√£o dispon√≠vel via proxy no momento.' };
}

/**
 * Verifica se a API est√° configurada correctly (agora sempre retorna true se houver URL do Python)
 */
export function isOpenAIConfigured(): boolean {
  return true; // Assumimos que o Python engine est√° configurado
}

/**
 * Limpa o thread (n√£o implementado no proxy b√°sico ainda)
 */
export function clearThread(dashboardId: string): void {
  console.log('üóëÔ∏è [OpenAI Proxy] Clear thread requested for:', dashboardId);
}

/**
 * Solicita uma interpreta√ß√£o completa do dataset para a IA
 * Retorna o JSON estruturado conforme o esquema de ai_decisions
 */
export async function askOpenAIForInterpretation(
  userId: string,
  dashboardId: string,
  context: {
    columns: ColumnInfo[];
    sampleData: Record<string, unknown>[];
    fileName: string;
    rowCount: number;
    intent?: string;
  }
): Promise<{ status: 'success' | 'error'; decision?: AiDecision; message?: string }> {
  console.log('üß† [OpenAI Proxy] Interpretation Request:', { fileName: context.fileName });
  return { status: 'error', message: 'Interpreta√ß√£o via proxy n√£o dispon√≠vel no momento.' };
}

// O ID do Assistente agora √© gerenciado pelo backend
export const ASSISTANT_ID = 'proxy';

